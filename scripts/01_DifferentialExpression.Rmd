---
title: "Differential expression analysis"
output:
  html_document: default
---

This tutorial is a compilation of tutorials from Sean Davis and Mike Love, with some modifications and additions to fit the objectives of this workshop.

```{r intro, echo=FALSE}
library(printr)
```

## The data

The data for this exercise are described in [Phenotypic responses of differentiated asthmatic human airway epithelial cultures to rhinovirus.", PLoS One, 2015 Feb 23;10(2):e0118286](https://www.ncbi.nlm.nih.gov/pubmed/25706956). 

> OBJECTIVES: Human airway epithelial cells are the principal target of human rhinovirus (HRV), a common cold pathogen that triggers the majority of asthma exacerbations. The objectives of this study were 1) to evaluate an in vitro air liquid interface cultured human airway epithelial cell model for HRV infection, and 2) to identify gene expression patterns associated with asthma intrinsically and/or after HRV infection using this model.
>
> METHODS: Air-liquid interface (ALI) human airway epithelial cell cultures were prepared from 6 asthmatic and 6 non-asthmatic donors. The effects of rhinovirus RV-A16 on ALI cultures were compared. Genome-wide gene expression changes in ALI cultures following HRV infection at 24 hours post exposure were further analyzed using RNA-seq technology. Cellular gene expression and cytokine/chemokine secretion were further evaluated by qPCR and a Luminex-based protein assay, respectively.
>
> MAIN RESULTS: ALI cultures were readily infected by HRV. RNA-seq analysis of HRV infected ALI cultures identified sets of genes associated with asthma specific viral responses. These genes are related to inflammatory pathways, epithelial structure and remodeling and cilium assembly and function, including those described previously (e.g. CCL5, CXCL10 and CX3CL1, MUC5AC, CDHR3), and novel ones that were identified for the first time in this study (e.g. CCRL1).
>
> CONCLUSIONS: ALI-cultured human airway epithelial cells challenged with HRV are a useful translational model for the study of HRV-induced responses in airway epithelial cells, given that gene expression profile using this model largely recapitulates some important patterns of gene responses in patients during clinical HRV infection. Furthermore, our data emphasize that both abnormal airway epithelial structure and inflammatory signaling are two important asthma signatures, which can be further exacerbated by HRV infection.

# Note on R package installations

If you get an error that says "there is no package called ‘NameOfPackage’", it means that don't have it installed and thus need to install that R package. You can do that by running the following lines of code (that uses as example the package "DESeq2")

```{r packageInstallation, eval=FALSE}
source("http://bioconductor.org/biocLite.R")
biocLite("DESeq2")
```

# Downloading data

We will use a publicly available dataset. This tutorial includes the process of how to download fastq files available through the Short Read Archive. The Short Read Archive is a database that contains sequencing data used in any publication. For most journals, it is a requirement to deposit any sequencing data used when submitting a paper for publication. When working with your own data, you would typically get fastq files from your sequencing facility.

## Reference files

We will be using the [Gencode reference transcripts](https://www.gencodegenes.org/releases/26.html) for this workflow. Since we are using an alignment-free quantification procedure, we will need the fasta files representing all transcripts and a GTF file for identifying which transcript isoforms go with which genes. Normally, you would use the website to identify the correct files and the download can be done with R using the following commands:

```{r}
download.file('ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_26/gencode.v26.transcripts.fa.gz',destfile = "gencode.v26.transcripts.fa.gz",quiet = TRUE)
download.file('ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_26/gencode.v26.chr_patch_hapl_scaff.annotation.gtf.gz',destfile = "gencode.v26.chr_patch_hapl_scaff.annotation.gtf.gz", quiet=TRUE)
```

Take your time to explore and understand these files!

## Raw reads (fastq)

The details on the data for this exercise are available from the [NCBI SRA here][RunTable]. The results from the SRA website were extracted and are available in the table below.  

```{r}
sra_run_table <- read.table('../data/SraRunTable.txt', sep = "\t", header = TRUE)
sra_run_table
```

However, the SRA data are stored in a proprietary format, so a [specific SRA toolkit][SRAToolkit] is necessary to get and the extract the data to FASTQ files. Here, we are going to use the SRA toolkit command `fastq-dump` to generate the fastq files (paired-end) for later mapping. 

The following function:

1. Constructs the command-line that we need as a string, called `cmdline`
2. Uses `system()` to call the command-line and run the command. Each SRA "Run" accession contains the fastq information for one sample. 

```{r}
extractSRA <- function(sra_accession,
                       exe_path = 'fastq-dump.2.8.2',
                       args = '--split-files --gzip',
                       outdir = 'fastq',
                       dry_run = FALSE) 
  {
    cmdline = sprintf('%s %s --outdir %s %s', exe_path, args, outdir, sra_accession)
    if(dry_run) {
      message("will run with this command line:\n",cmdline)
    } else {
      return(system(cmdline))
    }
  }
```

To give the function a try, we can execute the function as a "dry run", which will only give us the resulting command line, but will not have the computer execute it.

```{r}
extractSRA(sra_run_table$Run_s[1], dry_run = TRUE)
```

If we wanted to do run this for several samples at once and in parallel, we can use the `BiocParallel` package.

```{r}
library(BiocParallel)
```

The code below "registers" four "workers" and then extracts the first four samples worth of fastq files *at the same time*, or in parallel. Note that bplapply works very similarly to lapply except that the work is done in chunks of four at a time (or whatever the number of workers is). To keep things fast, we pass the parameter `-X 10000` to `fastq-dump` to generate only 10000 reads for each fastq file. 

```{r extractFASTQ,eval=FALSE}
#register(MulticoreParam(multicoreWorkers()))
res = bplapply(sra_run_table$Run_s, extractSRA, 
               args = "--split-files --gzip -X 10000", outdir = "incomplete_fastq")
```

So, if you now look in the "incomplete_fastq" directory, you'll see 48 files representing the forward and reverse reads for each of our 24 samples.

```{r}
head(dir('incomplete_fastq'))
```

# Quantifying RNA-seq with Salmon

Quantification with `salmon` is a two-step process. With other softwares, there may be more steps involved. Also, speed and output formats will generally vary quite a bit from one software to the next.

1. Generate an "index" from the transcript sequences. This need only be done once.
2. For each sample, run `salmon` in "quant" mode, specifying the correct index and fastq files for one sample. This step is run once for each sample.

## Creating the salmon index

Use the salmon software to first [create the index](http://salmon.readthedocs.io/en/latest/salmon.html#quasi-mapping-based-mode-including-lightweight-alignment) necessary before quantification.

```
# this needs to be typed into the command-line,
# not into R.
# 
# Use the salmon help (salmon index --help) to determing
# what the next line does.
salmon index -i gencode.v26 -t gencode.v26.transcripts.fa.gz -p 1
```

If we want to do the same thing directly from R, we simply need to wrap  the command lines in `system()`.

```{r eval=FALSE}
system("salmon index -i gencode.v26 -t gencode.v26.transcripts.fa.gz -p 1")
```

## Quantifying using salmon

Now, we can run salmon for the 24 samples of our experiment. Note that, for illustration purposes, we are running our quantifications using fastq files that contain only 10,000 reads. Thus the results of the quantifications will probably not representative of the whole dataset. However, the quantifications using the whole dataset are already available in the directory named 'data' of this repository. 

Below is a wrapper function in which we provide three parameters: a sample name, the indexed transcriptome generated in the previous step and an output directory. This wrapper will construct the call to salmon, which we pass to the linux terminal using the command `system`.

```{r}
salmon_quant <- function(samplename, index, fastqdir = 'incomplete_fastq') {
  cmdline = sprintf("salmon quant -i %s -1 %s/%s_1.fastq.gz -2 %s/%s_2.fastq.gz -l A -o %s/%s",
                    index, fastqdir, samplename, fastqdir, samplename, fastqdir, samplename)
  message(sprintf("running: %s\n", cmdline))
  system(cmdline)
}
```

Now, we can run the first sample.

```{r eval=FALSE}
salmon_quant('SRR1565929', "gencode.v26", 'incomplete_fastq')
```

To generalize this for all our samples, we will need to create a loop to run the `salmon_quant` function for each file.

```{r eval=FALSE}
for(run in sra_run_table$Run_s) {
  message("starting: ", run)
  salmon_quant(run, 'gencode.v26', "incomplete_fastq")
  message("finishing: ", run)
}
```

You will see that in the "incomplete_fastq" directory, there is one new directory for each sample, containing the results of the quantification step. Below, we are reading one of these files into our R session and exploring the first elements of it. Notice that there is an unusually high number of low  counts: this is because we only used a very small subset of the data!

```{r salmonResults, eval=FALSE}
dat = read.table('incomplete_fastq/SRR1565929/quant.sf')
head(dat)
```

Take a look at the [output files section](http://salmon.readthedocs.io/en/latest/file_formats.html#fileformats) of the salmon documentation. Then, look in the various sample directories. In particular, the quant.sf.gz files (one per sample) represent the transcript-level counts.

# Importing Salmon quant files

We will now import the Salmon quantifications into our R session. Note that we won't be
using the quantifications from our previous steps, since these don't
include all the reads from the data. Instead, we will be using the quantifications that are 
included in this repository under `data/quant`, which were done using the
whole data.

Relative to the `scripts` directory, the `real` quantifications can be found by typing:

```{r}
list.files("../data/quant/")
```

The layout of a single sample's quantification directory

```{r}
list.files("../data/quant/SRR1565926")
```

We will refer to the table we created from the SRA website, which
gives some of the sample information. We rename this table to `coldata`,
because it provides data about the *columns* of the count matrix
we will be assembling.

```{r}
coldata <- sra_run_table
coldata
```

We have used the run ID (`SRR...`) to keep track of the reads and quantifications,
so we can build a vector which points to our quantification files using
this column of `coldata`. We use `names` to name this vector with the run IDs as well.

```{r}
files <- file.path("../data/quant",coldata$Run_s,"quant.sf.gz")
names(files) <- coldata$Run_s
head(files,2)
```

The following code is used to generate a table
that connects transcripts to genes for summarizing Salmon transcript
quantifications for differential gene expression. We simply
read in the GTF file from the same database that we used for building
the Salmon index (in this case, Gencode version 26), and then pull
out a table with the transcript name for every gene.

```{r}
library(GenomicFeatures)
txdb <- makeTxDbFromGFF("gencode.v26.chr_patch_hapl_scaff.annotation.gtf.gz")
columns(txdb)
k <- keys(txdb, "GENEID")
res <- AnnotationDbi::select(txdb, k, "TXNAME", "GENEID")
tx2gene <- res[,2:1]
```
	
We explore the first lines of this object:

```{r}
head(tx2gene)
```

Now we can use the `tximport` function to assemble all the quantifications
from the 24 files, and to summarize the abundances, counts and transcript
lengths to the gene level, for use with DESeq2 and other Bioconductor
packages.

It's a good idea to first test on a single quantification file, which we show here:

```{r}
library(rjson)
library(tximport)
txi <- tximport(files[1], type="salmon", tx2gene=tx2gene)
```

Now we can run `tximport` over all the quanfitication files.
We can see we obtain a list of matrices with common dimension:
58219 (the number of genes) x 24 (the number of samples).

```{r message=FALSE}
txi <- tximport(files, type="salmon", tx2gene=tx2gene)
names(txi)
dim(txi$abundance)
dim(txi$counts)
dim(txi$length)
```

Now we load DESeq2 for further steps in the workflow:

```{r message=FALSE}
library(DESeq2)
```

# Assembling the sample info

In the `coldata` table, we have information about which samples are from
asthmatic or non-asthmatic individuals, and which samples are control or treated.
Because we built `txi` using the run IDs, we know that these columns are
lined up with our columns of the matrices in `txi`.

```{r}
coldata$disease_state_s
coldata$treatment_s
```

While most of the information we need is in the `coldata` table already,
while preparing this data for analysis, I noticed that the same subjects had 
both a control (Vehicle) and treated (HRV16) sample, but I didn't find this
information from the SRA table. It was present, however, in the title of 
the samples listed on the GEO website, which also points to the run ID.
We can therefore bring in the sample names from GEO, line them up with
our coldata, and extract the subject ID information:

```{r}
library(readr)
geo <- read_delim("../data/GEO_table.txt", delim="\t", col_names=FALSE)
head(geo)
coldata$title <- geo$X2[match(coldata$Sample_Name_s, geo$X1)]
coldata$condition <- factor(coldata$disease_state_s)
coldata$treatment <- factor(coldata$treatment_s)
```

Now, we will build a `DESeqDataSet` from the matrices in `txi`, 
which we will use for the rest of the workflow. This function brings
along the estimated counts per gene, estimated by Salmon, as well as 
a normalizing offset based on the transcript lengths. This normalizing offset
adjusts for the *average transcript length* of a gene, which can be influenced
by differential isoform usage, as well as common RNA-seq biases,
if we used Salmon flags for correcting for various biases. Both of these effects 
-- differential isoform usage and technical biases -- 
can change the *effective length* of a gene, and so both are useful as
normalizing offsets in a statistical comparisons of counts across samples.

When building the `DESeqDataSet` we have to specify a *design*, which
is a formula in R that begins with a tilde and explains what terms, or coefficients,
we want to use to model the counts. The design is used by the dispersion estimation
and model fitting functions in DESeq2, so we can change it later, but we will have 
to rerun the main functions to re-estimate the parameters. 

For now, we will use a design that specifies a condition effect (asthmatics vs
non-asthmatics), a treatment effect (HRV16 vs Vehicle), and an interaction between 
the two (so the treatment effect can be different for asthmatics and non-asthmatics).
An interaction term is specified in R with a colon between two variables.
This design roughly corresponds to the goals of the original study.
The samples are human airway epithelial cells, and so we can expect to see a reaction
in these cells upon treatment with virus.

```{r}
dds <- DESeqDataSetFromTximport(txi, coldata,
                                ~condition + treatment + condition:treatment)
dds
```

I like to rename the *levels* of the variables in the design so they are
easier to work with, by shortening them.

```{r}
# you can rename levels, but need to use same order as current levels()
levels(dds$condition)
levels(dds$condition) <- c("asth","non")
levels(dds$condition)
dds$condition
```

It's also important to set the *reference level* in a sensible way,
so comparisons are of treated over control for instance. In this 
case the reference levels should be the non-asthmatic individuals and the
Vehicle treatment.

We use the compound assignment operator `%<>%` from the magrittr package, 
which saves us a little extra typing, when we want to apply a function 
to a variable in R, and then re-assign it (so it is equivalent to `x <- f(x)`).

```{r}
library(magrittr)
dds$condition %<>% relevel("non")
dds$treatment %<>% relevel("Vehicle")
dds$condition
dds$treatment
```

# Parenthesis: downloading data from recount2

So far, we have seen how to go from raw fastq files to a `DESeqDataSet`, which is the object used for further analysis. As a brief parenthesis, recount2 is project in which the authors have processed more than 70,000 publicly available datasets and provide an R interphase to access them. For example, we can download processed data for our 24 samples using only a few lines of code:

```{r recount2}
library(recount)
studyID <- levels( coldata$SRA_Study_s )
download_study(studyID, type = "rse-gene")
load("SRP046226/rse_gene.RData")
as(rse_gene, "DESeqDataSet")
```

In a few lines of code, instead of all the previous lines of this tutorial, we have downloaded and generated a `DESeqDataSet` object that is ready to be analyzed. Of note, recount2 uses an alignment-based quantification approach that is different to the one we have been doing through this tutorial. If you are working with public data, it is likely that recount will save you months of work.

Closing parenthesis!

# Exploratory data analysis

Already, we can take a look at how the samples related to each other.
In DESeq2, we have special functions for transforming the counts,
so that they can be easily visualized (we will not transform the counts, 
but use the raw counts later, for statistical testing).

`vst` is a fast function that provides transformed (nearly log-scale) data which is
robust to many problems associated with log-transformed data (for more details,
see the DESeq2 
[workflow ](http://www.bioconductor.org/help/workflows/rnaseqGene/#the-rlog-and-variance-stabilizing-transformations)
or 
[vignette](https://www.bioconductor.org/packages/release/bioc/vignettes/DESeq2/inst/doc/DESeq2.html#count-data-transformations)
).

`blind=FALSE` refers to the fact that we will use the *design* in estimating
the global scale of biological variability, but not directly in the transformation:

```{r}
vsd <- vst(dds, blind=FALSE)
```

Now that we have normalized and transformed the data, it will have roughly 
the same variance (except for differentially expressed genes) across the range of
counts, so from counts in the single digits, up to the most highly expressed 
genes with very high counts.

We can make a PCA plot, which shows the distribution of the samples
among the top two dimensions, in terms of the variance explained.
It's simply a rotation and projection of the transformed data, but 
picking the "best" 2 dimensions out of the tens of thousands (number of genes).

```{r pca, fig.width=7, fig.height=4}
plotPCA(vsd, c("treatment","condition"))
```

From the PCA plot, we see that the treatment with HRV leads to the most
variance across samples, for the top variable genes. There seems to be some
clustering by disease status (what we called `condition`), for the treated samples
but not much for the control samples.

# Re-arrange sample info

As we mentioned before, there is an additional piece of information
about the samples: the Vehicle and HRV treated samples are from
the same individual, so this is also important information to include
in the design, if possible. In this case, because we are comparing
control and HRV treatment within individuals, we can add this information 
to the design. First, we need to clean up the sample ID information
contained in the `title` variable:

```{r}
dds$id <- substr(dds$title, 1, 3)
dds$id
id.lvls <- c(dds$id[dds$condition == "non" & dds$treatment == "Vehicle"],
             dds$id[dds$condition == "asth" & dds$treatment == "Vehicle"])
id.lvls
```

We will re-factor the id, so that the levels are in the order
of the `id.lvls` variable we just defined.

We will then re-order the `DESeqDataSet` so that the
samples are in order by condition, treatment and ID.

```{r}
dds$id %<>% factor(levels=id.lvls)
o <- order(dds$condition, dds$treatment, dds$id)
dds <- dds[,o]
```

We can take a look at the `colData` to confirm it's in the order
as we want it to be:

```{r}
as.data.frame(colData(dds)[c("condition","treatment","id")])
all(dds$id == c(rep(id.lvls[1:6], 2),
                rep(id.lvls[7:12], 2)))
```

To make the within-individual treatment comparisons across 
condition, we need to do a little re-coding trick for the 
subject ID. We will re-code them so that the first asthmatic 
subject is called `1`, and the first non-asthmatic subject 
is also called `1`, which we call "nesting". 

Note that these two subjects will 
not be treated as the same in the model, because we will
include an interaction term between `condition` and `id.nested`.

```{r}
dds$id.nested <- factor(rep(1:6,4))
as.data.frame(colData(dds)[c("condition","treatment","id","id.nested")])
```

Now we update the design, so that each patient gets his or her 
own reference level for comparison of the treatment effect:

```{r}
design(dds) <- ~condition + condition:id.nested +
  treatment + condition:treatment
```

Before we run the differential expression steps,
we have one more data cleaning step to do. We will 
chop off the version number of the gene IDs, so that we 
can better look up their annotation information later.

However, we have a few genes which would have duplicated
gene IDs after chopping off the version number, so in order
to proceed we have to also use `make.unique` to indicate 
that some genes are duplicated. (It might be 
worth looking into why we have multiple versions of genes
with the same base ID coming from our annotation.)

```{r}
head(rownames(dds))
table(duplicated(substr(rownames(dds),1,15)))
rownames(dds) <- make.unique(substr(rownames(dds),1,15))
```

# Differential gene expression

Now we can run our differential expression pipeline.
First, it is sometimes convenient to remove genes where
all the samples have very small counts. It's less of an issue 
for the statistical methods, and mostly just wasted computation,
as it is not possible for these genes to exhibit statistical
significance for differential expression. Here we count
how many genes (out of those with at least a single count)
have 3 samples with a count of 10 or more:

```{r}
dds <- dds[rowSums(counts(dds)) > 0,]
keep <- rowSums(counts(dds) >= 10) >= 3
table(keep)
dds <- dds[keep,] # filter them out
```

Now we can run the differential expression pipeline using
`DESeq` and extract the results using `results`.
These functions do a little of work for you, and
they have extensive help describing all their options,
which can be read by typing in `?DESeq` and `?results`.

We will build a results table for the coefficient
`conditionasth.treatmentHRV16`. This coefficient represents
the difference in the treatment effect in the asthmatic group
relative to the non-asthmatic group.

```{r}
dds <- DESeq(dds)
resultsNames(dds)
res <- results(dds, name="conditionasth.treatmentHRV16")
res.sort <- res[order(res$pvalue),]
```

# Exploring results

A good visual summary of a results table is the "MA-plot".
M stands for "minus", as the y-axis for a simple two group
comparison is the difference between the log of the expression
values for each group. In general, and for this experiment, the y-axis
is the log2 fold change attributable to the coefficient or contrast
that was used in building the results table. The "A" stands for average,
as the x-axis indicates the average of normalized counts across 
all the samples in the dataset.

Because all of the points are grey, we know that none of the 
genes showed a significant difference in the treatment effect
across the two condition groups, at an FDR cutoff of 0.1 
(this is the default value for `plotMA`, and can be changed).

```{r plotma}
plotMA(res, ylim=c(-5,5))
```

We can also print out a summary table, which 
similarly tells us that, at an FDR cutoff of 0.1,
no genes were significantly differentially expressed
for our particular comparison.

```{r}
summary(res)
```

```{r echo=FALSE}
# to make plotCounts same each time
# (has random jitter)
# avoids inflation of git repo...
set.seed(1)
```

While we didn't get any genes at an FDR cutoff of 0.1, we can
look at the top gene by adjusted p-value, in 
terms of the normalized counts in the different groups.

There does seem to be a trend of downregulation of this gene
for non-asthmatics, and up-regulation for asthmatics, 
but generally the fold changes across treatment are not very
consistent within conditions.

We've added the ID within each condition as a plotting character
`pch`:

```{r topgene1, fig.width=7, fig.height=5}
top.gene <- rownames(res.sort)[1]
plotCounts(dds, top.gene, c("condition","treatment"), 
           transform=FALSE, pch=as.integer(dds$id.nested))
```

We can also make a plot which draws lines
between the expression values across treatment for a given sample.
To do so, we need to use the `ggplot2` library. First, we 
export a little table of the counts and design variables 
for the top gene:

```{r}
dat <- plotCounts(dds, top.gene, c("condition","treatment","id.nested"),
                  returnData=TRUE)
```

Next we form the `ggplot2` code, using points and a smooth line
to connect the points for each ID in each condition group.
It makes sense that this is the top gene for testing different slope
across condition, but the slopes are not entirely consistent
across the samples within a condition, which explains why
it's not more significant in the hypothesis test.

```{r targets2, warning=FALSE, fig.width=7, fig.height=4}
library(ggplot2)
ggplot(dat, aes(x=treatment, y=count, col=id.nested, group=id.nested)) +
  geom_point() + geom_smooth(method="lm", se=FALSE) +
  scale_y_log10() + 
  facet_wrap(~condition)
```

We can look up the gene symbol for the top gene using an annotation package.
These packages have a number of functions for pulling out annotations,
here we will show the `mapIds` function and the `select` function.
`select` is the name for a function in the `dplyr` package,
so we have to use the package prefix `AnnotationDbi::` to call
our version of `select`.

The other command is for looking up gene ontology terms for the top gene, 
specifically terms that are classified as biological processes (BP).
We will explore GO terms further in a later section of this workflow.

```{r}
library(org.Hs.eg.db)
org.Hs.eg.db %>% mapIds(top.gene, "SYMBOL", "ENSEMBL")
go.tab <- org.Hs.eg.db %>% AnnotationDbi::select(top.gene, "GO", "ENSEMBL") %>% subset(ONTOLOGY == "BP")
go.tab
```

A number of gene symbols were listed in the abstract of the paper 
(one of which we swapped here for a more common gene symbol).
We can do a reverse lookup, to see where they are showing up
in our list of ranked genes:

```{r}
target <- c("CCL5","CXCL10","CX3CL1","ACKR4","CDHR3")
target.map <- mapIds(org.Hs.eg.db, target, "ENSEMBL", "SYMBOL")
target.map
match(target.map, rownames(res.sort))
```

Let's take a look at the counts for the second gene symbol from above:

```{r targets, fig.width=7, fig.height=5}
plotCounts(dds, target.map[2], c("condition","treatment"))
plotCounts(dds, target.map[2], c("condition","treatment"), transform=FALSE)
```

# Other differential analyses

Now that we've taken a look at how power depends on effect size and mean count 
(among other things like design, number of replicates and dispersion),
let's return to our dataset, and try different statistical analyses,
besides the test of differences across condition in the treatment effect.

We didn't seem to see much of a difference in the treatment effect
across condition, so we can try another design, in which we estimate
the same treatment effect in both conditions, comparing within
subjects.

```{r}
dds2 <- removeResults(dds)
design(dds2) <- ~condition + treatment + condition:id.nested
dds2 <- DESeq(dds2)
resultsNames(dds2)
res2 <- results(dds2, name="treatment_HRV16_vs_Vehicle")
```

The above results table is equivalent, produced with the `name` argument
is equivalent to using the `contrast` argument, and providing
the numerator and denominator for the contrast:

```{r}
res2 <- results(dds2, contrast=c("treatment","HRV16","Vehicle"))
```

We can again make an MA plot, and notice that there are now
many genes which show large and significant log2 fold changes.
Also, one can see that most of the genes with log2 fold change 
larger than 2 in absolute value are in the top, meaning
that we are seeing genes with large up-regulation upon HRV treatment.

```{r plotma2}
plotMA(res2, ylim=c(-10,10))
```

```{r}
summary(res2)
```

We will take a look at the genes with large, positive log2 fold change
(greater than 2), and sort by the log2 fold change.

Looking at the gene names, some of the symbols look familiar, 
e.g. the ones with `CXCL...` and `CCL5`. These genes code for chemokines,
which are signaling molecules in the cell, and it makes sense to see these
up-regulated after treatment with virus, as the cells are mounting an
immune defense.

```{r}
res2.up <- results(dds2, name="treatment_HRV16_vs_Vehicle", 
                   lfcThreshold=1, altHypothesis="greater")
res2.up <- res2.up[res2.up$padj < .1,]
res2.sort <- res2.up[order(res2.up$log2FoldChange, decreasing=TRUE),]
org.Hs.eg.db %>% mapIds(rownames(res2.sort)[1:40],
                        "SYMBOL", "ENSEMBL")
```

Note that some of the top genes from the abstract are high on this list
of genes differentially expressed upon viral treatment.

```{r}
match(target.map, rownames(res2.sort))
```

# Exploring results with annotation

We can dive deeper into the top genes, by looking up
what biological processes these are associated with.

```{r}
go.tab <- org.Hs.eg.db %>% AnnotationDbi::select(rownames(res2.sort)[1],
                                  "GO", "ENSEMBL") %>% subset(ONTOLOGY == "BP")
go.tab
```

Now that we have associated this gene with a set of GO terms, we can look up
their names. Sometimes the names are very long, so to fit on the screen
we will chop the name at 60 characters.

The biological processes have names like "inflamation response", "immune response",
"response to cold", and "defense response to virus", which make sense.

```{r}
library(GO.db)
go.tab2 <- GO.db %>% AnnotationDbi::select(go.tab$GO, "TERM", "GOID")
substr(go.tab2$TERM, 1, 60)
```

We can write a function which prints out the GO term names for a given gene in our
results table:

```{r}
getTerms <- function(n) {
  go.tab <- org.Hs.eg.db %>% AnnotationDbi::select(rownames(res2.sort)[n],
              "GO", "ENSEMBL") %>% subset(ONTOLOGY == "BP")
  go.tab2 <- GO.db %>% AnnotationDbi::select(go.tab$GO, "TERM", "GOID")
  substr(go.tab2$TERM, 1, 60)
}
```

We see a lot of these immune response terms, but again
the proper way to do this would be (1) to have a specific
process in mind (no peeking at these lists first),
or (2) to test against a battery of GO-defined gene sets
of a certain size.

```{r}
getTerms(2)
getTerms(3)
getTerms(4)
getTerms(5)
getTerms(6)
```

# Testing for over-represented gene sets

The exploratory analysis from the previous section is useful to get an idea of the annotation of the genes that are differentially expressed. However, the appropiate way to look at this is to blindly test for over-represented gene sets among the genes that are differentially expressed as compared to a background set of genes. This statistically test, for example, if the treatment is causing the transcription of genes from a specific biological pathway. 

In RNA-seq, the counts of a gene are biased due to, among other things, gene length. The longer the gene, the more it is likely to have more counts and thus more power to be detected as differentially expressed. The package `goseq` is a package to test for over-representation of gene sets that is specifically designed to account for gene length biases. 

We load the goseq library and prepare a vector of zeros and ones. The name of each element of the vector will correspond to a gene, such that differentially expressed genes are flagged with a one. 

```{r goseq}
library(goseq)
genes <- as.numeric( res2$padj < 0.1 )
names( genes ) <- rownames( res2 )
head( genes )
```

We run the Probability Weighting Function from the `goseq` package, that estimates the gene length bias. The resulting plot is informative of this bias. 

```{r }
pwf=nullp(genes,"hg19","ensGene")
```

We know use the function `goseq` to calculate a p-value for each GO cathegory, which results from testing whether a GO cathegory is over-represented among the genes that are differentially expressed. The resulting table is ranked by p-value: among the 10 GO cathegories with smaller p-values, we can see that we get terms related to immune responses. 

```{r gotest}
GO.wall=goseq(pwf,"hg19","ensGene")
head( GO.wall )
head( GO.wall )
```

# Conclusion

This tutorial has guided you through an analysis of differential expression using RNA-seq data. It went from quantifying expression from raw fastq files and ended in gene set enrichment analyses that enables the generation of biological conclusions. 

# Session info

```{r}
sessionInfo()
```


[RunTable]: https://trace.ncbi.nlm.nih.gov/Traces/study/?acc=SRP046226
[SRAStudy]: https://trace.ncbi.nlm.nih.gov/Traces/sra/?study=SRP046226
[salmonrelease]: https://github.com/COMBINE-lab/salmon/releases
[NCBISRA]: https://www.ncbi.nlm.nih.gov/sra
[SRAToolkit]: https://www.ncbi.nlm.nih.gov/sra/docs/toolkitsoft/
[recount2]: https://jhubiostatistics.shinyapps.io/recount/
